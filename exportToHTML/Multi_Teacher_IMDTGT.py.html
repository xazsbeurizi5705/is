<html>
<head>
<title>Multi_Teacher_IMDTGT.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #a9b7c6;}
.s1 { color: #cc7832;}
.s2 { color: #6897bb;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
Multi_Teacher_IMDTGT.py</font>
</center></td></tr></table>
<pre>
<span class="s1">import </span><span class="s0">os</span>
<span class="s1">import </span><span class="s0">random</span>
<span class="s1">from </span><span class="s0">copy </span><span class="s1">import </span><span class="s0">deepcopy</span>


<span class="s1">import </span><span class="s0">numpy </span><span class="s1">as </span><span class="s0">np</span>
<span class="s1">import </span><span class="s0">torch</span>
<span class="s1">from </span><span class="s0">matplotlib </span><span class="s1">import </span><span class="s0">pyplot </span><span class="s1">as </span><span class="s0">plt</span>
<span class="s1">from </span><span class="s0">timm.models.layers </span><span class="s1">import </span><span class="s0">DropPath</span>
<span class="s1">from </span><span class="s0">torch.nn.modules.dropout </span><span class="s1">import </span><span class="s0">_DropoutNd</span>

<span class="s1">from </span><span class="s0">mmseg.core </span><span class="s1">import </span><span class="s0">add_prefix</span>
<span class="s1">from </span><span class="s0">mmseg.models </span><span class="s1">import </span><span class="s0">UDA</span><span class="s1">, </span><span class="s0">build_segmentor</span>
<span class="s1">from </span><span class="s0">mmseg.models.uda.uda_decorator </span><span class="s1">import </span><span class="s0">UDADecorator</span><span class="s1">, </span><span class="s0">get_module</span>
<span class="s1">from </span><span class="s0">mmseg.models.utils.dacs_transforms </span><span class="s1">import </span><span class="s0">(denorm</span><span class="s1">, </span><span class="s0">get_class_masks</span><span class="s1">,</span>
                                                <span class="s0">get_mean_std</span><span class="s1">, </span><span class="s0">strong_transform)</span>
<span class="s1">from </span><span class="s0">mmseg.models.utils.visualization </span><span class="s1">import </span><span class="s0">subplotimg</span>



<span class="s1">def </span><span class="s0">get_ema_model(self):</span>
    <span class="s1">return </span><span class="s0">get_module(self.ema_model)</span>

<span class="s1">def </span><span class="s0">_init_ema_weights(self):</span>
    <span class="s1">for </span><span class="s0">param </span><span class="s1">in </span><span class="s0">self.get_ema_model().parameters():</span>
        <span class="s0">param.detach_()</span>
    <span class="s0">mp = list(self.get_model().parameters())</span>
    <span class="s0">mcp = list(self.get_ema_model().parameters())</span>
    <span class="s1">for </span><span class="s0">i </span><span class="s1">in </span><span class="s0">range(</span><span class="s2">0</span><span class="s1">, </span><span class="s0">len(mp)):</span>
        <span class="s1">if not </span><span class="s0">mcp[i].data.shape:  </span><span class="s3"># scalar tensor</span>
            <span class="s0">mcp[i].data = mp[i].data.clone()</span>
        <span class="s1">else</span><span class="s0">:</span>
            <span class="s0">mcp[i].data[:] = mp[i].data[:].clone()</span>

<span class="s1">def </span><span class="s0">freeze_module(model):</span>
    <span class="s1">for </span><span class="s0">p </span><span class="s1">in </span><span class="s0">model.parameters():</span>
        <span class="s0">p.requires_grad = </span><span class="s1">False</span>

<span class="s0">@UDA.register_module()</span>
<span class="s1">class </span><span class="s0">MultiTeacherIMDTGT(UDADecorator):</span>
    <span class="s1">def </span><span class="s0">__int__(self</span><span class="s1">, </span><span class="s0">**cfg):</span>
        <span class="s0">super(MultiTeacherIMDTGT</span><span class="s1">, </span><span class="s0">self).__init__(**cfg)</span>
        <span class="s0">self.local_iter = </span><span class="s2">0</span>
        <span class="s0">self.max_iters = cfg[</span><span class="s4">'max_iters'</span><span class="s0">]</span>
        <span class="s0">self.alpha = cfg[</span><span class="s4">'alpha'</span><span class="s0">]</span>
        <span class="s0">self.pseudo_threshold = cfg[</span><span class="s4">'pseudo_threshold'</span><span class="s0">]</span>
        <span class="s0">self.psweight_ignore_top = cfg[</span><span class="s4">'pseudo_weight_ignore_top'</span><span class="s0">]</span>
        <span class="s0">self.psweight_ignore_bottom = cfg[</span><span class="s4">'pseudo_weight_ignore_bottom'</span><span class="s0">]</span>
        <span class="s0">self.psweight_ref_ignore_top = cfg[</span><span class="s4">'pseudo_ref_weight_ignore_top'</span><span class="s0">]</span>
        <span class="s0">self.mix = cfg[</span><span class="s4">'mix'</span><span class="s0">]</span>
        <span class="s0">self.blur = cfg[</span><span class="s4">'blur'</span><span class="s0">]</span>
        <span class="s0">self.color_jitter_s = cfg[</span><span class="s4">'color_jitter_strength'</span><span class="s0">]</span>
        <span class="s0">self.color_jitter_p = cfg[</span><span class="s4">'color_jitter_probability'</span><span class="s0">]</span>
        <span class="s0">self.debug_img_interval = cfg[</span><span class="s4">'debug_img_interval'</span><span class="s0">]</span>
        <span class="s0">self.class_probs = {}</span>
        <span class="s0">self.teacher_model_target = build_segmentor(deepcopy(cfg[</span><span class="s4">'model'</span><span class="s0">]))</span>
        <span class="s0">self.teacher_model_imd = build_segmentor(deepcopy(cfg[</span><span class="s4">'model'</span><span class="s0">]))</span>

    <span class="s1">def </span><span class="s0">_update_ema(self</span><span class="s1">, </span><span class="s0">iter):</span>
        <span class="s0">alpha_teacher = min(</span><span class="s2">1 </span><span class="s0">- </span><span class="s2">1 </span><span class="s0">/ (iter + </span><span class="s2">1</span><span class="s0">)</span><span class="s1">, </span><span class="s0">self.alpha)</span>
        <span class="s1">for </span><span class="s0">ema_param</span><span class="s1">, </span><span class="s0">param </span><span class="s1">in </span><span class="s0">zip(self.get_ema_model().parameters()</span><span class="s1">,</span>
                                    <span class="s0">self.get_model().parameters()):</span>
            <span class="s1">if not </span><span class="s0">param.data.shape:  </span><span class="s3"># scalar tensor</span>
                <span class="s0">ema_param.data = \</span>
                    <span class="s0">alpha_teacher * ema_param.data + \</span>
                    <span class="s0">(</span><span class="s2">1 </span><span class="s0">- alpha_teacher) * param.data</span>
            <span class="s1">else</span><span class="s0">:</span>
                <span class="s0">ema_param.data[:] = \</span>
                    <span class="s0">alpha_teacher * ema_param[:].data[:] + \</span>
                    <span class="s0">(</span><span class="s2">1 </span><span class="s0">- alpha_teacher) * param[:].data[:]</span>


    <span class="s1">def </span><span class="s0">train_step(self</span><span class="s1">, </span><span class="s0">data_batch</span><span class="s1">, </span><span class="s0">optimizer</span><span class="s1">, </span><span class="s0">**kwargs):</span>

        <span class="s0">optimizer.zero_grad()</span>
        <span class="s0">log_vars = self(**data_batch)</span>
        <span class="s0">optimizer.step()</span>

        <span class="s0">log_vars.pop(</span><span class="s4">'loss'</span><span class="s1">, None</span><span class="s0">)  </span><span class="s3"># remove the unnecessary 'loss'</span>
        <span class="s0">outputs = dict(</span>
            <span class="s0">log_vars=log_vars</span><span class="s1">, </span><span class="s0">num_samples=len(data_batch[</span><span class="s4">'img_metas'</span><span class="s0">]))</span>
        <span class="s1">return </span><span class="s0">outputs</span>

    <span class="s1">def </span><span class="s0">forward_train(self</span><span class="s1">,</span>
                      <span class="s0">img</span><span class="s1">,</span>
                      <span class="s0">img_metas</span><span class="s1">,</span>
                      <span class="s0">gt_semantic_seg=</span><span class="s1">None,</span>
                      <span class="s0">imd_img=</span><span class="s1">None,</span>
                      <span class="s0">imd_img_metas=</span><span class="s1">None,</span>
                      <span class="s0">target_img=</span><span class="s1">None,</span>
                      <span class="s0">target_img_metas=</span><span class="s1">None,</span><span class="s0">):</span>

        <span class="s0">log_vars = {}</span>
        <span class="s0">batch_size = img.shape[</span><span class="s2">0</span><span class="s0">]</span>
        <span class="s0">dev = img.device</span>

        <span class="s0">means</span><span class="s1">,</span><span class="s0">stds=get_mean_std(img_metas</span><span class="s1">,</span><span class="s0">dev)</span>

        <span class="s0">strong_parameters = {</span><span class="s4">'mix'</span><span class="s0">: </span><span class="s1">None, </span><span class="s4">'color_jitter'</span><span class="s0">: random.uniform(</span><span class="s2">0</span><span class="s1">, </span><span class="s2">1</span><span class="s0">)</span><span class="s1">, </span><span class="s4">'color_jitter_s'</span><span class="s0">: self.color_jitter_s</span><span class="s1">, </span><span class="s4">'color_jitter_p'</span><span class="s0">: self.color_jitter_p</span><span class="s1">, </span><span class="s4">'blur'</span><span class="s0">: random.uniform(</span><span class="s2">0</span><span class="s1">, </span><span class="s2">1</span><span class="s0">) </span><span class="s1">if </span><span class="s0">self.blur </span><span class="s1">else </span><span class="s2">0</span><span class="s1">, </span><span class="s4">'mean'</span><span class="s0">: means[</span><span class="s2">0</span><span class="s0">].unsqueeze(</span><span class="s2">0</span><span class="s0">)</span><span class="s1">, </span><span class="s4">'std'</span><span class="s0">: stds[</span><span class="s2">0</span><span class="s0">].unsqueeze(</span><span class="s2">0</span><span class="s0">)}</span>

        <span class="s1">if </span><span class="s0">self.local_iter == </span><span class="s2">0</span><span class="s0">:</span>
            <span class="s0">_init_ema_weights(module=self.get_model()</span><span class="s1">,</span>

                             <span class="s0">module_ema=get_module(self.teacher_model_imd))</span>
            <span class="s0">_init_ema_weights(module=self.get_model()</span><span class="s1">,</span>
                             <span class="s0">module_ema=get_module(self.teacher_model_target))</span>

            <span class="s0">freeze_module(get_module(self.teacher_model_imd))</span>
            <span class="s0">freeze_module(get_module(self.teacher_model_target))</span>

        <span class="s1">if </span><span class="s0">self.local_iter &gt; </span><span class="s2">0</span><span class="s0">:</span>
            <span class="s0">clean_losses = self.get_model().forward_train(</span>
                <span class="s0">img</span><span class="s1">, </span><span class="s0">img_metas</span><span class="s1">, </span><span class="s0">gt_semantic_seg</span><span class="s1">, </span><span class="s0">return_feat=</span><span class="s1">False</span>
            <span class="s0">)</span>
            <span class="s0">clean_losses = add_prefix(clean_losses</span><span class="s1">, </span><span class="s4">'src'</span><span class="s0">)</span>
            <span class="s0">clean_loss</span><span class="s1">, </span><span class="s0">clean_log_vars = self._parse_losses(clean_losses)</span>
            <span class="s0">log_vars.update(clean_log_vars)</span>
            <span class="s0">clean_loss.backward(retain_graph=</span><span class="s1">False</span><span class="s0">)</span>

        <span class="s1">if </span><span class="s0">self.local_iter % </span><span class="s2">2 </span><span class="s0">== </span><span class="s2">0</span><span class="s0">:</span>
            <span class="s0">self._update_ema(self.local_iter</span><span class="s1">,</span>
                             <span class="s0">module=self.get_model()</span><span class="s1">,</span>
                             <span class="s0">module_ema=get_module(self.teacher_model_imd))</span>
        <span class="s1">for </span><span class="s0">m </span><span class="s1">in </span><span class="s0">get_module(self.teacher_model_imd).modules():</span>
            <span class="s1">if </span><span class="s0">isinstance(m</span><span class="s1">, </span><span class="s0">_DropoutNd):</span>
                <span class="s0">m.training = </span><span class="s1">False</span>
            <span class="s1">if </span><span class="s0">isinstance(m</span><span class="s1">, </span><span class="s0">DropPath):</span>
                <span class="s0">m.training = </span><span class="s1">False</span>
        <span class="s0">imd_ema_logits = get_module(self.teacher_model_imd).encode_decode(</span>
            <span class="s0">imd_img</span><span class="s1">, </span><span class="s0">imd_img_metas)</span>
        <span class="s0">imd_ema_softmax = torch.softmax(imd_ema_logits.detach()</span><span class="s1">, </span><span class="s0">dim=</span><span class="s2">1</span><span class="s0">)</span>
        <span class="s0">imd_pseudo_prob</span><span class="s1">, </span><span class="s0">imd_pseudo_label = torch.max(imd_ema_softmax</span><span class="s1">, </span><span class="s0">dim=</span><span class="s2">1</span><span class="s0">)</span>
        <span class="s0">imd_ps_large_p = imd_pseudo_prob.ge(self.pseudo_threshold).long() == </span><span class="s2">1</span>
        <span class="s0">imd_ps_size = np.size(np.array(imd_pseudo_label.cpu()))</span>
        <span class="s0">imd_pseudo_weight = torch.sum(imd_ps_large_p).item() / imd_ps_size</span>
        <span class="s0">imd_pseudo_weight = imd_pseudo_weight * torch.ones(imd_pseudo_prob.shape</span><span class="s1">, </span><span class="s0">device=dev)</span>

        <span class="s1">if </span><span class="s0">self.psweight_ignore_top &gt; </span><span class="s2">0</span><span class="s0">:</span>
            <span class="s0">imd_pseudo_weight[:</span><span class="s1">, </span><span class="s0">:self.psweight_ignore_top</span><span class="s1">, </span><span class="s0">:] = </span><span class="s2">0</span>
        <span class="s1">if </span><span class="s0">self.psweight_ignore_bottom &gt; </span><span class="s2">0</span><span class="s0">:</span>
            <span class="s0">imd_pseudo_weight[:</span><span class="s1">, </span><span class="s0">-self.psweight_ignore_bottom:</span><span class="s1">, </span><span class="s0">:] = </span><span class="s2">0</span>
        <span class="s0">imd_gt_pixel_weight = torch.ones(imd_pseudo_weight.shape</span><span class="s1">, </span><span class="s0">device=dev)</span>

        <span class="s0">src_imd_mixed_img</span><span class="s1">, </span><span class="s0">src_imd_mixed_lbl = [</span><span class="s1">None</span><span class="s0">] * batch_size</span><span class="s1">, </span><span class="s0">[</span><span class="s1">None</span><span class="s0">] * batch_size</span>
        <span class="s0">src_imd_mix_masks = get_class_masks(gt_semantic_seg)</span>

        <span class="s1">for </span><span class="s0">i </span><span class="s1">in </span><span class="s0">range(batch_size):</span>
            <span class="s0">strong_parameters[</span><span class="s4">'mix'</span><span class="s0">] = src_imd_mix_masks[i]</span>
            <span class="s0">src_imd_mixed_img[i]</span><span class="s1">, </span><span class="s0">src_imd_mixed_lbl[i] = strong_transform(</span>
                <span class="s0">strong_parameters</span><span class="s1">,</span>
                <span class="s0">data=torch.stack((img[i]</span><span class="s1">, </span><span class="s0">imd_img[i]))</span><span class="s1">,</span>
                <span class="s0">target=torch.stack((gt_semantic_seg[i][</span><span class="s2">0</span><span class="s0">]</span><span class="s1">, </span><span class="s0">imd_pseudo_label[i])))</span>
            <span class="s0">_</span><span class="s1">, </span><span class="s0">imd_pseudo_weight[i] = strong_transform(strong_parameters</span><span class="s1">, </span><span class="s0">target=torch.stack((imd_gt_pixel_weight[i]</span><span class="s1">, </span><span class="s0">imd_pseudo_weight[i])))</span>
        <span class="s0">src_imd_mixed_img = torch.cat(src_imd_mixed_img)</span>
        <span class="s0">src_imd_mixed_lbl = torch.cat(src_imd_mixed_lbl)</span>

        <span class="s0">src_imd_mix_losses = self.get_model().forward_train(</span>
            <span class="s0">src_imd_mixed_img</span><span class="s1">, </span><span class="s0">img_metas</span><span class="s1">, </span><span class="s0">src_imd_mixed_lbl</span><span class="s1">, </span><span class="s0">imd_pseudo_weight</span><span class="s1">, </span><span class="s0">return_feat=</span><span class="s1">True</span>
        <span class="s0">)</span>
        <span class="s0">src_imd_mix_losses.pop(</span><span class="s4">'features'</span><span class="s0">)</span>
        <span class="s0">src_imd_mix_losses = add_prefix(src_imd_mix_losses</span><span class="s1">, </span><span class="s4">'src_imd_mix'</span><span class="s0">)</span>
        <span class="s0">src_imd_mix_loss</span><span class="s1">, </span><span class="s0">src_imd_mix_log_vars = self._parse_losses(src_imd_mix_losses)</span>
        <span class="s0">log_vars.update(src_imd_mix_log_vars)</span>
        <span class="s0">src_imd_mix_loss.backward()</span>

        <span class="s1">if </span><span class="s0">self.local_iter % </span><span class="s2">2 </span><span class="s0">== </span><span class="s2">1</span><span class="s0">:</span>
            <span class="s0">self._update_ema(self.local_iter</span><span class="s1">,</span>
                             <span class="s0">module=self.get_model()</span><span class="s1">,</span>
                             <span class="s0">module_ema=get_module(self.teacher_model_target))</span>
        <span class="s1">for </span><span class="s0">m </span><span class="s1">in </span><span class="s0">get_module(self.teacher_model_target).modules():</span>
            <span class="s1">if </span><span class="s0">isinstance(m</span><span class="s1">, </span><span class="s0">_DropoutNd):</span>
                <span class="s0">m.training = </span><span class="s1">False</span>
            <span class="s1">if </span><span class="s0">isinstance(m</span><span class="s1">, </span><span class="s0">DropPath):</span>
                <span class="s0">m.training = </span><span class="s1">False</span>
        <span class="s0">ema_logits = get_module(self.teacher_model_target).encode_decode(</span>
            <span class="s0">target_img</span><span class="s1">, </span><span class="s0">target_img_metas)</span>
        <span class="s0">ema_softmax = torch.softmax(ema_logits.detach()</span><span class="s1">, </span><span class="s0">dim=</span><span class="s2">1</span><span class="s0">)</span>
        <span class="s0">pseudo_prob</span><span class="s1">, </span><span class="s0">pseudo_label = torch.max(ema_softmax</span><span class="s1">, </span><span class="s0">dim=</span><span class="s2">1</span><span class="s0">)</span>
        <span class="s0">ps_large_p = pseudo_prob.ge(self.pseudo_threshold).long() == </span><span class="s2">1</span>
        <span class="s0">ps_size = np.size(np.array(pseudo_label.cpu()))</span>
        <span class="s0">pseudo_weight = torch.sum(ps_large_p).item() / ps_size</span>
        <span class="s0">pseudo_weight = pseudo_weight * torch.ones(pseudo_prob.shape</span><span class="s1">, </span><span class="s0">device=dev)</span>

        <span class="s1">if </span><span class="s0">self.psweight_ignore_top &gt; </span><span class="s2">0</span><span class="s0">:</span>
            <span class="s0">pseudo_weight[:</span><span class="s1">, </span><span class="s0">:self.psweight_ignore_top</span><span class="s1">, </span><span class="s0">:] = </span><span class="s2">0</span>
        <span class="s1">if </span><span class="s0">self.psweight_ignore_bottom &gt; </span><span class="s2">0</span><span class="s0">:</span>
            <span class="s0">pseudo_weight[:</span><span class="s1">, </span><span class="s0">-self.psweight_ignore_bottom:</span><span class="s1">, </span><span class="s0">:] = </span><span class="s2">0</span>
        <span class="s0">gt_pixel_weight = torch.ones(pseudo_weight.shape</span><span class="s1">, </span><span class="s0">device=dev)</span>

        <span class="s0">mixed_img</span><span class="s1">, </span><span class="s0">mixed_lbl = [</span><span class="s1">None</span><span class="s0">] * batch_size</span><span class="s1">, </span><span class="s0">[</span><span class="s1">None</span><span class="s0">] * batch_size</span>
        <span class="s0">mix_masks = get_class_masks(gt_semantic_seg)</span>

        <span class="s1">for </span><span class="s0">i </span><span class="s1">in </span><span class="s0">range(batch_size):</span>
            <span class="s0">strong_parameters[</span><span class="s4">'mix'</span><span class="s0">] = mix_masks[i]</span>
            <span class="s0">mixed_img[i]</span><span class="s1">, </span><span class="s0">mixed_lbl[i] = strong_transform(</span>
                <span class="s0">strong_parameters</span><span class="s1">,</span>
                <span class="s0">data=torch.stack((img[i]</span><span class="s1">, </span><span class="s0">target_img[i]))</span><span class="s1">,</span>
                <span class="s0">target=torch.stack((gt_semantic_seg[i][</span><span class="s2">0</span><span class="s0">]</span><span class="s1">, </span><span class="s0">pseudo_label[i])))</span>
            <span class="s0">_</span><span class="s1">, </span><span class="s0">pseudo_weight[i] = strong_transform(strong_parameters</span><span class="s1">, </span><span class="s0">target=torch.stack((gt_pixel_weight[i]</span><span class="s1">, </span><span class="s0">pseudo_weight[i])))</span>
        <span class="s0">mixed_img = torch.cat(mixed_img)</span>
        <span class="s0">mixed_lbl = torch.cat(mixed_lbl)</span>

        <span class="s0">mix_losses = self.get_model().forward_train(</span>
            <span class="s0">mixed_img</span><span class="s1">, </span><span class="s0">img_metas</span><span class="s1">, </span><span class="s0">mixed_lbl</span><span class="s1">, </span><span class="s0">pseudo_weight</span><span class="s1">, </span><span class="s0">return_feat=</span><span class="s1">True</span>
        <span class="s0">)</span>
        <span class="s0">mix_losses.pop(</span><span class="s4">'features'</span><span class="s0">)</span>
        <span class="s0">mix_losses = add_prefix(mix_losses</span><span class="s1">, </span><span class="s4">'src_imd_mix'</span><span class="s0">)</span>
        <span class="s0">mix_loss</span><span class="s1">, </span><span class="s0">mix_log_vars = self._parse_losses(mix_losses)</span>
        <span class="s0">log_vars.update(mix_log_vars)</span>
        <span class="s0">mix_loss.backward()</span>

        <span class="s1">if </span><span class="s0">self.local_iter % self.debug_img_interval == </span><span class="s2">0</span><span class="s0">:</span>
            <span class="s0">out_dir = os.path.join(self.train_cfg[</span><span class="s4">'work_dir'</span><span class="s0">]</span><span class="s1">,</span>
                                   <span class="s4">'class_mix_debug'</span><span class="s0">)</span>
            <span class="s0">os.makedirs(out_dir</span><span class="s1">, </span><span class="s0">exist_ok=</span><span class="s1">True</span><span class="s0">)</span>
            <span class="s0">vis_img = torch.clamp(denorm(img</span><span class="s1">, </span><span class="s0">means</span><span class="s1">, </span><span class="s0">stds)</span><span class="s1">, </span><span class="s2">0</span><span class="s1">, </span><span class="s2">1</span><span class="s0">)</span>
            <span class="s0">vis_trg_img = torch.clamp(denorm(target_img</span><span class="s1">, </span><span class="s0">means</span><span class="s1">, </span><span class="s0">stds)</span><span class="s1">, </span><span class="s2">0</span><span class="s1">, </span><span class="s2">1</span><span class="s0">)</span>
            <span class="s0">vis_mixed_img = torch.clamp(denorm(mixed_img</span><span class="s1">, </span><span class="s0">means</span><span class="s1">, </span><span class="s0">stds)</span><span class="s1">, </span><span class="s2">0</span><span class="s1">, </span><span class="s2">1</span><span class="s0">)</span>
            <span class="s1">for </span><span class="s0">j </span><span class="s1">in </span><span class="s0">range(batch_size):</span>
                <span class="s0">rows</span><span class="s1">, </span><span class="s0">cols = </span><span class="s2">2</span><span class="s1">, </span><span class="s2">5</span>
                <span class="s0">fig</span><span class="s1">, </span><span class="s0">axs = plt.subplots(</span>
                    <span class="s0">rows</span><span class="s1">,</span>
                    <span class="s0">cols</span><span class="s1">,</span>
                    <span class="s0">figsize=(</span><span class="s2">3 </span><span class="s0">* cols</span><span class="s1">, </span><span class="s2">3 </span><span class="s0">* rows)</span><span class="s1">,</span>
                    <span class="s0">gridspec_kw={</span>
                        <span class="s4">'hspace'</span><span class="s0">: </span><span class="s2">0.1</span><span class="s1">,</span>
                        <span class="s4">'wspace'</span><span class="s0">: </span><span class="s2">0</span><span class="s1">,</span>
                        <span class="s4">'top'</span><span class="s0">: </span><span class="s2">0.95</span><span class="s1">,</span>
                        <span class="s4">'bottom'</span><span class="s0">: </span><span class="s2">0</span><span class="s1">,</span>
                        <span class="s4">'right'</span><span class="s0">: </span><span class="s2">1</span><span class="s1">,</span>
                        <span class="s4">'left'</span><span class="s0">: </span><span class="s2">0</span>
                    <span class="s0">}</span><span class="s1">,</span>
                <span class="s0">)</span>
                <span class="s0">subplotimg(axs[</span><span class="s2">0</span><span class="s0">][</span><span class="s2">0</span><span class="s0">]</span><span class="s1">, </span><span class="s0">vis_img[j]</span><span class="s1">, </span><span class="s4">'Source Image'</span><span class="s0">)</span>
                <span class="s0">subplotimg(axs[</span><span class="s2">1</span><span class="s0">][</span><span class="s2">0</span><span class="s0">]</span><span class="s1">, </span><span class="s0">vis_trg_img[j]</span><span class="s1">, </span><span class="s4">'Target Image'</span><span class="s0">)</span>
                <span class="s0">subplotimg(</span>
                    <span class="s0">axs[</span><span class="s2">0</span><span class="s0">][</span><span class="s2">1</span><span class="s0">]</span><span class="s1">,</span>
                    <span class="s0">gt_semantic_seg[j]</span><span class="s1">,</span>
                    <span class="s4">'Source Seg GT'</span><span class="s1">,</span>
                    <span class="s0">cmap=</span><span class="s4">'cityscapes'</span><span class="s0">)</span>
                <span class="s0">subplotimg(</span>
                    <span class="s0">axs[</span><span class="s2">1</span><span class="s0">][</span><span class="s2">1</span><span class="s0">]</span><span class="s1">,</span>
                    <span class="s0">pseudo_label[j]</span><span class="s1">,</span>
                    <span class="s4">'Target Seg (Pseudo) GT'</span><span class="s1">,</span>
                    <span class="s0">cmap=</span><span class="s4">'cityscapes'</span><span class="s0">)</span>
                <span class="s0">subplotimg(axs[</span><span class="s2">0</span><span class="s0">][</span><span class="s2">2</span><span class="s0">]</span><span class="s1">, </span><span class="s0">vis_mixed_img[j]</span><span class="s1">, </span><span class="s4">'Mixed Image'</span><span class="s0">)</span>
                <span class="s0">subplotimg(</span>
                    <span class="s0">axs[</span><span class="s2">1</span><span class="s0">][</span><span class="s2">2</span><span class="s0">]</span><span class="s1">, </span><span class="s0">mix_masks[j][</span><span class="s2">0</span><span class="s0">]</span><span class="s1">, </span><span class="s4">'Domain Mask'</span><span class="s1">, </span><span class="s0">cmap=</span><span class="s4">'gray'</span><span class="s0">)</span>
                <span class="s3"># subplotimg(axs[0][3], pred_u_s[j], &quot;Seg Pred&quot;,</span>
                <span class="s3">#            cmap=&quot;cityscapes&quot;)</span>
                <span class="s0">subplotimg(</span>
                    <span class="s0">axs[</span><span class="s2">1</span><span class="s0">][</span><span class="s2">3</span><span class="s0">]</span><span class="s1">, </span><span class="s0">mixed_lbl[j]</span><span class="s1">, </span><span class="s4">'Seg Targ'</span><span class="s1">, </span><span class="s0">cmap=</span><span class="s4">'cityscapes'</span><span class="s0">)</span>
                <span class="s0">subplotimg(</span>
                    <span class="s0">axs[</span><span class="s2">0</span><span class="s0">][</span><span class="s2">3</span><span class="s0">]</span><span class="s1">, </span><span class="s0">pseudo_weight[j]</span><span class="s1">, </span><span class="s4">'Pseudo W.'</span><span class="s1">, </span><span class="s0">vmin=</span><span class="s2">0</span><span class="s1">, </span><span class="s0">vmax=</span><span class="s2">1</span><span class="s0">)</span>
                <span class="s1">if </span><span class="s0">self.debug_fdist_mask </span><span class="s1">is not None</span><span class="s0">:</span>
                    <span class="s0">subplotimg(</span>
                        <span class="s0">axs[</span><span class="s2">0</span><span class="s0">][</span><span class="s2">4</span><span class="s0">]</span><span class="s1">,</span>
                        <span class="s0">self.debug_fdist_mask[j][</span><span class="s2">0</span><span class="s0">]</span><span class="s1">,</span>
                        <span class="s4">'FDist Mask'</span><span class="s1">,</span>
                        <span class="s0">cmap=</span><span class="s4">'gray'</span><span class="s0">)</span>
                <span class="s1">if </span><span class="s0">self.debug_gt_rescale </span><span class="s1">is not None</span><span class="s0">:</span>
                    <span class="s0">subplotimg(</span>
                        <span class="s0">axs[</span><span class="s2">1</span><span class="s0">][</span><span class="s2">4</span><span class="s0">]</span><span class="s1">,</span>
                        <span class="s0">self.debug_gt_rescale[j]</span><span class="s1">,</span>
                        <span class="s4">'Scaled GT'</span><span class="s1">,</span>
                        <span class="s0">cmap=</span><span class="s4">'cityscapes'</span><span class="s0">)</span>
                <span class="s1">for </span><span class="s0">ax </span><span class="s1">in </span><span class="s0">axs.flat:</span>
                    <span class="s0">ax.axis(</span><span class="s4">'off'</span><span class="s0">)</span>
                <span class="s0">plt.savefig(</span>
                    <span class="s0">os.path.join(out_dir</span><span class="s1">,</span>
                                 <span class="s4">f'</span><span class="s1">{</span><span class="s0">(self.local_iter + </span><span class="s2">1</span><span class="s0">)</span><span class="s1">:</span><span class="s4">06d</span><span class="s1">}</span><span class="s4">_</span><span class="s1">{</span><span class="s0">j</span><span class="s1">}</span><span class="s4">.png'</span><span class="s0">))</span>
                <span class="s0">plt.close()</span>
        <span class="s0">self.local_iter += </span><span class="s2">1</span>

        <span class="s1">return </span><span class="s0">log_vars</span>
</pre>
</body>
</html>